# Pretrain_Bert_with_MaskLM

## Info
ä½¿ç”¨Mask LMé è¨“ç·´ä»»å‹™ä¾†é è¨“ç·´Bertæ¨¡å‹ã€‚

åŸºæ–¼pytorchæ¡†æ¶ï¼Œè¨“ç·´é—œæ–¼å‚ç›´é ˜åŸŸèªæ–™çš„é è¨“ç·´èªè¨€æ¨¡å‹ï¼Œç›®çš„æ˜¯æå‡ä¸‹æ¸¸ä»»å‹™çš„è¡¨ç¾ã€‚




## Pretraining Task
Mask Language Modelï¼Œç°¡ç¨±Mask LMï¼Œå³åŸºæ–¼Maskæ©Ÿåˆ¶çš„é è¨“ç·´èªè¨€æ¨¡å‹ã€‚

åŒæ™‚æ”¯æŒ åŸç”Ÿçš„`MaskLM`ä»»å‹™å’Œ`Whole Words Masking`ä»»å‹™ã€‚é»˜èªä½¿ç”¨`Whole Words Masking`ã€‚

#### MaskLM
ä½¿ç”¨ä¾†è‡ªæ–¼Bertçš„maskæ©Ÿåˆ¶ï¼Œå³å°æ–¼æ¯ä¸€å€‹å¥å­ä¸­çš„è©ï¼ˆtokenï¼‰ï¼š
* 85%çš„æ¦‚ç‡ï¼Œä¿ç•™åŸè©ä¸è®Š
* 15%çš„æ¦‚ç‡ï¼Œä½¿ç”¨ä»¥ä¸‹æ–¹å¼æ›¿æ›
    * 80%çš„æ¦‚ç‡ï¼Œä½¿ç”¨å­—ç¬¦`[MASK]`ï¼Œæ›¿æ›ç•¶å‰tokenã€‚
    * 10%çš„æ¦‚ç‡ï¼Œä½¿ç”¨è©è¡¨éš¨æ©ŸæŠ½å–çš„tokenï¼Œæ›¿æ›ç•¶å‰tokenã€‚
    * 10%çš„æ¦‚ç‡ï¼Œä¿ç•™åŸè©ä¸è®Šã€‚
    <!-- * ![](./picture/mask_method.png) -->
    * <img src=./picture/mask_method.png width=50% />

#### Whole Words Masking
èˆ‡MaskLMé¡ä¼¼ï¼Œä½†æ˜¯åœ¨maskçš„æ­¥é©Ÿæœ‰äº›å°‘ä¸åŒã€‚

åœ¨Berté¡æ¨¡å‹ä¸­ï¼Œè€ƒæ…®åˆ°å¦‚æœå–®ç¨ä½¿ç”¨æ•´å€‹è©ä½œç‚ºè©è¡¨çš„è©±ï¼Œé‚£è©è¡¨å°±å¤ªå¤§äº†ã€‚ä¸åˆ©æ–¼æ¨¡å‹å°åŒé¡è©çš„ä¸åŒè®Šç¨®çš„ç‰¹å¾µå­¸ç¿’ï¼Œæ•…æ¡ç”¨äº†WordPieceçš„æ–¹å¼é€²è¡Œåˆ†è©ã€‚

`Whole Words Masking`çš„æ–¹æ³•åœ¨æ–¼ï¼Œåœ¨é€²è¡Œmaskæ“ä½œæ™‚ï¼Œå°åƒè®Šç‚ºåˆ†è©å‰çš„æ•´å€‹è©ï¼Œè€Œéå­è©ã€‚


## Model
ä½¿ç”¨åŸç”Ÿçš„Bertæ¨¡å‹ä½œç‚ºåŸºæº–æ¨¡å‹ã€‚
* ![](./picture/bert_architecture.png)



## Datasets
é …ç›®è£¡çš„æ•¸æ“šé›†ä¾†è‡ª`wikitext`ï¼Œåˆ†æˆå…©å€‹æ–‡ä»¶è¨“ç·´é›†ï¼ˆtrain.txtï¼‰å’Œæ¸¬è©¦é›†ï¼ˆtest.txtï¼‰ã€‚

æ•¸æ“šä»¥è¡Œç‚ºå–®ä½å­˜å„²ã€‚

è‹¥æƒ³è¦æ›¿æ›æˆè‡ªå·±çš„æ•¸æ“šé›†ï¼Œå¯ä»¥ä½¿ç”¨è‡ªå·±çš„æ•¸æ“šé›†é€²è¡Œæ›¿æ›ã€‚ ï¼ˆæ³¨æ„ï¼šå¦‚æœæ˜¯é è¨“ç·´ä¸­æ–‡æ¨¡å‹ï¼Œéœ€è¦ä¿®æ”¹é…ç½®æ–‡ä»¶`Config.py`ä¸­çš„`self.initial_pretrain_model`å’Œ`self.initial_pretrain_tokenizer`ï¼Œå°‡å€¼ä¿®æ”¹æˆ `bert-base-chinese`ï¼‰

è‡ªå·±çš„æ•¸æ“šé›†ä¸éœ€è¦åšmaskæ©Ÿåˆ¶è™•ç†ï¼Œä»£ç¢¼æœƒè™•ç†ã€‚


## Training Target
æœ¬é …ç›®ç›®çš„åœ¨æ–¼åŸºæ–¼ç¾æœ‰çš„é è¨“ç·´æ¨¡å‹åƒæ•¸ï¼Œå¦‚googleé–‹æºçš„`bert-base-uncased`ã€`bert-base-chinese`ç­‰ï¼Œåœ¨å‚ç›´é ˜åŸŸçš„æ•¸æ“šèªæ–™ä¸Šï¼Œå†æ¬¡é€²è¡Œé è¨“ç·´ä»»å‹™ï¼Œç”±æ­¤æå‡bertçš„æ¨¡å‹è¡¨å¾µèƒ½åŠ›ï¼Œæ›å¥è©±èªªï¼Œä¹Ÿå°±æ˜¯æå‡ä¸‹æ¸¸ä»»å‹™çš„è¡¨ç¾ã€‚


## Environment

é …ç›®ä¸»è¦ä½¿ç”¨äº†Huggingfaceçš„`datasets`ã€`transformers`æ¨¡å¡Šï¼Œæ”¯æŒCPUã€å–®å¡å–®æ©Ÿã€å–®æ©Ÿå¤šå¡ä¸‰ç¨®æ¨¡å¼ã€‚

pythonçš„ç‰ˆæœ¬ç‚º: 3.8

å¯é€šéä»¥ä¸‹å‘½ä»¤å®‰è£ä¾è³´åŒ…
```
    pip install -r requirement.txt
```
ä¸»è¦åŒ…å«çš„æ¨¡å¡Šå¦‚ä¸‹ï¼š
```
    numpy==1.24.1
    pandas==1.5.2
    scikit_learn==1.2.1
    torch==1.8.0
    tqdm==4.64.1
    transformers==4.26.1
```



## Get Start

### å–®å¡æ¨¡å¼
(1) è¨“ç·´

ç›´æ¥é‹è¡Œ
```
    python main.py
```

(2) æ¸¬è©¦

ä¿®æ”¹`Config.py`æ–‡ä»¶ä¸­çš„`self.mode='test'`ï¼Œå†é‹è¡Œ
```
    python main.py
```

### å¤šå¡æ¨¡å¼ï¼ˆè¨“ç·´ï¼‰
å¦‚æœä½ è¶³å¤ å¹¸é‹ï¼Œæ“æœ‰äº†å¤šå¼µGPUå¡ï¼Œé‚£éº¼æ­å–œä½ ï¼Œä½ å¯ä»¥é€²å…¥èµ·é£›æ¨¡å¼ã€‚ğŸš€ğŸš€

ï¼ˆ1ï¼‰ä½¿ç”¨torchçš„`nn.parallel.DistributedDataParallel`æ¨¡å¡Šé€²è¡Œå¤šå¡è¨“ç·´ã€‚å…¶ä¸­`config.py`æ–‡ä»¶ä¸­åƒæ•¸å¦‚ä¸‹ï¼Œé»˜èªå¯ä»¥ä¸ç”¨ä¿®æ”¹ã€‚

* <font color=#009393>`self.cuda_visible_devices`è¡¨ç¤ºç¨‹åºå¯è¦‹çš„GPUå¡è™Ÿï¼Œç¤ºä¾‹ï¼š`1,2`â†’å¯åœ¨GPUå¡è™Ÿç‚º1å’Œ2ä¸Šè·‘ï¼Œäº¦å¯ä»¥æ”¹å¤šå¼µï¼Œå¦‚`0,1,2,3`ã€‚</font>
* <font color=#009393>`self.device`åœ¨å–®å¡æ¨¡å¼ï¼Œè¡¨ç¤ºç¨‹åºé‹è¡Œçš„å¡è™Ÿï¼›åœ¨å¤šå¡æ¨¡å¼ä¸‹ï¼Œè¡¨ç¤ºmasterçš„ä¸»å¡ï¼Œé»˜èªæœƒè®Šæˆä½ æŒ‡å®šå¡è™Ÿçš„ç¬¬ä¸€å¼µå¡ã€‚è‹¥åªæœ‰cpuï¼Œé‚£éº¼å¯ä¿®æ”¹ç‚º`cpu`ã€‚</font>
* <font color=#009393>`self.port`è¡¨ç¤ºå¤šå¡æ¨¡å¼ä¸‹ï¼Œé€²ç¨‹é€šä¿¡ä½”ç”¨çš„ç«¯å£è™Ÿã€‚ ï¼ˆç„¡éœ€ä¿®æ”¹ï¼‰</font>
* <font color=#009393>`self.init_method`è¡¨ç¤ºå¤šå¡æ¨¡å¼ä¸‹é€²ç¨‹çš„é€šè¨Šåœ°å€ã€‚ ï¼ˆç„¡éœ€ä¿®æ”¹ï¼‰</font>
* <font color=#009393>`self.world_size`è¡¨ç¤ºå•Ÿå‹•çš„é€²ç¨‹æ•¸é‡ï¼ˆç„¡éœ€ä¿®æ”¹ï¼‰ã€‚åœ¨torch==1.3.0ç‰ˆæœ¬ä¸‹ï¼Œåªéœ€æŒ‡å®šä¸€å€‹é€²ç¨‹ã€‚åœ¨1.9.0ä»¥ä¸Šï¼Œéœ€è¦èˆ‡GPUæ•¸é‡ç›¸åŒã€‚</font>

# Experiment

## training
ä½¿ç”¨äº¤å‰ç†µï¼ˆcross-entropyï¼‰ä½œç‚ºæå¤±å‡½æ•¸ï¼Œå›°æƒ‘åº¦ï¼ˆperplexityï¼‰å’ŒLossä½œç‚ºè©•åƒ¹æŒ‡æ¨™ä¾†é€²è¡Œè¨“ç·´ï¼Œè¨“ç·´éç¨‹å¦‚ä¸‹ï¼š
<!-- ![](./picture/experiment.png) -->
<img src=./picture/experiment.png width=70% />

## test
çµæœä¿å­˜åœ¨`dataset/output/pred_data.csv`ï¼Œåˆ†åˆ¥åŒ…å«ä¸‰åˆ—ï¼š
- `src`è¡¨ç¤ºåŸå§‹è¼¸å…¥
- `pred`è¡¨ç¤ºæ¨¡å‹é æ¸¬
- `mask`è¡¨ç¤ºæ¨¡å‹è¼¸å…¥ï¼ˆå¸¶æœ‰maskå’Œpadç­‰tokenï¼‰

ç¤ºä¾‹

```
src:  [CLS] art education and first professional work [SEP]
pred: [CLS] art education and first class work [SEP]
mask: [CLS] art education and first [MASK] work [SEP] [PAD] [PAD] [PAD] ...
```


# Reference

ã€Bertã€‘[https://arxiv.org/pdf/1810.04805.pdf](https://arxiv.org/pdf/1810.04805.pdf)

ã€transformersã€‘[https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)

ã€datasetsã€‘[https://huggingface.co/docs/datasets/quicktour.html](https://huggingface.co/docs/datasets/quicktour.html)




